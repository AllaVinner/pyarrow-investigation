{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Is Memory Read?\n",
    "Working with large files we do not want to read things into memory, or at least not all at once.\n",
    "This notebooks investigate when functions in pyarrow is actually reading memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scripts.memory_methods' from 'C:\\\\Users\\\\jottosso\\\\Documents\\\\programming\\\\python\\\\pyarrow-investigation\\\\notebooks\\\\scripts\\\\memory_methods.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jarrow.util as util\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import os\n",
    "import scripts.memory_methods as funs\n",
    "import numpy as np\n",
    "import importlib\n",
    "importlib.reload(funs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('.', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tmp table.\n",
    "input_path = os.path.join(data_path, 'tmp', 'input')\n",
    "util.write_parquet(input_path, num_rows=6000, partitions=['c_cat', 'c_cat2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: C:\\Users\\jottosso\\Documents\\programming\\python\\pyarrow-investigation\\notebooks\\scripts\\memory_methods.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    18    196.4 MiB    196.4 MiB           1   @profile\n",
      "    19                                         def process_dataset(input_path, output_path):\n",
      "    20    196.4 MiB      0.0 MiB           1       a = 1\n",
      "    21    196.5 MiB      0.1 MiB           1       dataset = ds.dataset(input_path, partitioning=\"hive\", format='parquet')\n",
      "    22    196.5 MiB      0.0 MiB           1       sc = dataset.scanner(filter=ds.field('c_float') > 0)\n",
      "    23    216.1 MiB     19.6 MiB           1       tbl = dataset.to_table()\n",
      "    24    228.5 MiB     12.4 MiB           1       ds.write_dataset(tbl,os.path.join(output_path, 'tbl'), partitioning_flavor='hive', format='parquet')\n",
      "    25    233.6 MiB      5.1 MiB           1       ds.write_dataset(sc,os.path.join(output_path, 'sc'), partitioning_flavor='hive', format='parquet')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(data_path, 'tmp', 'output')\n",
    "util.clear_directory(output_path)\n",
    "funs.process_dataset(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdf\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b157c68f3c05e0e81317543c8d7fd774a9ccf4e50bfad1f2f01f4b8528efeb14"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}